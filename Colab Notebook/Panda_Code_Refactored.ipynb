{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPn4TpghVLR5tNAfeCDH55K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek09thakur/PANDA/blob/main/Colab%20Notebook/Panda_Code_Refactored.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Refactored Code of PANDA**"
      ],
      "metadata": {
        "id": "TfRp-aOrhzaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] **DRIVE MOUNTED**"
      ],
      "metadata": {
        "id": "iy2VJ6njiH-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEfD_cdXhFOV",
        "outputId": "99c0f565-d899-4fd6-ee4f-d02755dfead6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] **A Refactored version Paradigm based Artificial Neural Dailogue Agent (P.A.N.D.A)**"
      ],
      "metadata": {
        "id": "bDNOlF9CiREj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z-dwaQdmf1e-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense,LSTM,Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "\n",
        "class PANDA:\n",
        "\n",
        "    def __init__(self,prompts,model_name,tokens=25):\n",
        "        self.prompts = prompts\n",
        "        self.tokens = tokens\n",
        "        with open(self.prompts,'r') as f:\n",
        "            # Read the lines from the prompts file\n",
        "            self.text_data = f.readlines()\n",
        "        # Create a tokenizer\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.tokenizer.fit_on_texts(self.text_data)\n",
        "        self.total_words = len(self.tokenizer.word_index) + 1\n",
        "        self.model_name = model_name\n",
        "        # self.max_sequence_len = 0\n",
        "\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        self.input_sequences = []\n",
        "        self.next_words = []\n",
        "        for line in self.text_data:\n",
        "            # Convert the text to sequences\n",
        "            token_list = self.tokenizer.texts_to_sequences([line])[0]\n",
        "            for i in range(1,len(token_list)):\n",
        "                # Create n-grams\n",
        "                n_grams = token_list[:i+1]\n",
        "                self.input_sequences.append(n_grams)\n",
        "                self.next_words.append(token_list[i])\n",
        "\n",
        "    def generate_pad_sequences(self):\n",
        "        # Pad sequences\n",
        "        self.max_sequence_len = max([len(x) for x in self.input_sequences])\n",
        "        self.input_sequences = np.array(\n",
        "            pad_sequences(self.input_sequences,\n",
        "                          maxlen=self.max_sequence_len,padding='pre'))\n",
        "        self.predictors, self.label = self.input_sequences[:, :-1], self.input_sequences[:, -1]\n",
        "\n",
        "    def create_model(self,number_of_neurons):\n",
        "        # Create model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(self.total_words,100,\n",
        "                                 input_length=self.max_sequence_len-1))\n",
        "        self.model.add(LSTM(number_of_neurons))\n",
        "        self.model.add(Dense(self.total_words,activation='softmax'))\n",
        "        self.model.compile(loss='sparse_categorical_crossentropy',\n",
        "                           optimizer='adam',metrics=['accuracy'])\n",
        "        self.model.fit(self.predictors,self.label,epochs=500,\n",
        "                       verbose=1)\n",
        "        self.model.save(self.model_name)\n",
        "\n",
        "    def load_model(self):\n",
        "        self.model = load_model(self.model_name)\n",
        "\n",
        "    def train_or_load_model(self,neuron_num):\n",
        "        if os.path.exists(self.model_name):\n",
        "            self.load_model()\n",
        "        else:\n",
        "            self.create_model(number_of_neurons=neuron_num)\n",
        "\n",
        "    def completion(self,user_input):\n",
        "        # Predictions\n",
        "        token_list = self.tokenizer.texts_to_sequences([user_input])[0]\n",
        "        token_list = pad_sequences([token_list],\n",
        "                                      maxlen=self.max_sequence_len-1,\n",
        "                                      padding='pre')\n",
        "        predicted_words = []\n",
        "\n",
        "        for _ in range(self.tokens):\n",
        "            predicted = self.model.predict(token_list,verbose=0)\n",
        "            predicted_index = np.argmax(predicted)\n",
        "            output_word = ''\n",
        "            for word,index in self.tokenizer.word_index.items():\n",
        "                if index == predicted_index:\n",
        "                    output_word = word\n",
        "                    break\n",
        "            predicted_words.append(output_word)\n",
        "            token_list = np.append(token_list[:,1:],[[predicted_index]],axis=1)\n",
        "        return ' '.join(predicted_words)\n",
        "\n",
        "    def type_response(self,response):\n",
        "        for char in response:\n",
        "            sys.stdout.write(char)\n",
        "            sys.stdout.flush()\n",
        "            time.sleep(0.01)\n",
        "        print()\n",
        "\n",
        "    def introduce(self):\n",
        "        print('Hello, I am PANDA, Paradgim-based Artificial Neural Dialogue Agent. An AI Language Model which is able to predict next sequence of words based on the input sequence of words.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] **Test Run**"
      ],
      "metadata": {
        "id": "PUpu8jN5imZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Dataset/PANDA_LLM/prompts.txt', # prompts file\n",
        "    'Saved Model/panda.h5', # model name\n",
        "     25 # number of tokens to generate\n",
        "]\n",
        "\n",
        "panda = PANDA(parameters[0],parameters[1],parameters[2])\n",
        "panda.preprocess_data()\n",
        "panda.generate_pad_sequences()\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    panda.train_or_load_model(neuron_num=1000)\n",
        "    panda.introduce()\n",
        "\n",
        "    while True:\n",
        "        prompts = input(f\"\\n â†³ (user) : \" )\n",
        "        completion = panda.completion(prompts)\n",
        "        panda.type_response(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GB_L4ZUiiqxt",
        "outputId": "3353b456-a114-474e-83d2-f72bb8e1122b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "688/688 [==============================] - 34s 40ms/step - loss: 6.1687 - accuracy: 0.0505\n",
            "Epoch 2/500\n",
            "688/688 [==============================] - 17s 24ms/step - loss: 5.4392 - accuracy: 0.0986\n",
            "Epoch 3/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 4.8956 - accuracy: 0.1370\n",
            "Epoch 4/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 4.2596 - accuracy: 0.1735\n",
            "Epoch 5/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 3.3871 - accuracy: 0.2602\n",
            "Epoch 6/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 2.3442 - accuracy: 0.4510\n",
            "Epoch 7/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4718 - accuracy: 0.6674\n",
            "Epoch 8/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9764 - accuracy: 0.7781\n",
            "Epoch 9/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7602 - accuracy: 0.8234\n",
            "Epoch 10/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6531 - accuracy: 0.8416\n",
            "Epoch 11/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6068 - accuracy: 0.8523\n",
            "Epoch 12/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5696 - accuracy: 0.8606\n",
            "Epoch 13/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5553 - accuracy: 0.8659\n",
            "Epoch 14/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5379 - accuracy: 0.8700\n",
            "Epoch 15/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5422 - accuracy: 0.8668\n",
            "Epoch 16/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5195 - accuracy: 0.8707\n",
            "Epoch 17/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4851 - accuracy: 0.8773\n",
            "Epoch 18/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4726 - accuracy: 0.8787\n",
            "Epoch 19/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4602 - accuracy: 0.8800\n",
            "Epoch 20/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4603 - accuracy: 0.8792\n",
            "Epoch 21/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4498 - accuracy: 0.8802\n",
            "Epoch 22/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4863 - accuracy: 0.8701\n",
            "Epoch 23/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5649 - accuracy: 0.8515\n",
            "Epoch 24/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4436 - accuracy: 0.8772\n",
            "Epoch 25/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4210 - accuracy: 0.8813\n",
            "Epoch 26/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4213 - accuracy: 0.8808\n",
            "Epoch 27/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4189 - accuracy: 0.8817\n",
            "Epoch 28/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4209 - accuracy: 0.8805\n",
            "Epoch 29/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4175 - accuracy: 0.8824\n",
            "Epoch 30/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4206 - accuracy: 0.8820\n",
            "Epoch 31/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5703 - accuracy: 0.8422\n",
            "Epoch 32/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5197 - accuracy: 0.8546\n",
            "Epoch 33/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4055 - accuracy: 0.8814\n",
            "Epoch 34/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3951 - accuracy: 0.8814\n",
            "Epoch 35/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3962 - accuracy: 0.8824\n",
            "Epoch 36/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3984 - accuracy: 0.8815\n",
            "Epoch 37/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4007 - accuracy: 0.8811\n",
            "Epoch 38/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3994 - accuracy: 0.8817\n",
            "Epoch 39/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4014 - accuracy: 0.8816\n",
            "Epoch 40/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4202 - accuracy: 0.8771\n",
            "Epoch 41/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6601 - accuracy: 0.8127\n",
            "Epoch 42/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4316 - accuracy: 0.8717\n",
            "Epoch 43/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3878 - accuracy: 0.8825\n",
            "Epoch 44/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3832 - accuracy: 0.8827\n",
            "Epoch 45/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3837 - accuracy: 0.8827\n",
            "Epoch 46/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3861 - accuracy: 0.8817\n",
            "Epoch 47/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3862 - accuracy: 0.8834\n",
            "Epoch 48/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3882 - accuracy: 0.8831\n",
            "Epoch 49/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3872 - accuracy: 0.8825\n",
            "Epoch 50/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3878 - accuracy: 0.8821\n",
            "Epoch 51/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5079 - accuracy: 0.8512\n",
            "Epoch 52/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.6661 - accuracy: 0.8062\n",
            "Epoch 53/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4138 - accuracy: 0.8753\n",
            "Epoch 54/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3761 - accuracy: 0.8832\n",
            "Epoch 55/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3734 - accuracy: 0.8833\n",
            "Epoch 56/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3737 - accuracy: 0.8844\n",
            "Epoch 57/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3762 - accuracy: 0.8834\n",
            "Epoch 58/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3780 - accuracy: 0.8821\n",
            "Epoch 59/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3784 - accuracy: 0.8833\n",
            "Epoch 60/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3793 - accuracy: 0.8838\n",
            "Epoch 61/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3806 - accuracy: 0.8822\n",
            "Epoch 62/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7285 - accuracy: 0.7878\n",
            "Epoch 63/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5262 - accuracy: 0.8432\n",
            "Epoch 64/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3986 - accuracy: 0.8771\n",
            "Epoch 65/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3724 - accuracy: 0.8834\n",
            "Epoch 66/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3683 - accuracy: 0.8844\n",
            "Epoch 67/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3712 - accuracy: 0.8832\n",
            "Epoch 68/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3721 - accuracy: 0.8833\n",
            "Epoch 69/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3736 - accuracy: 0.8824\n",
            "Epoch 70/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3754 - accuracy: 0.8821\n",
            "Epoch 71/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4463 - accuracy: 0.8641\n",
            "Epoch 72/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6894 - accuracy: 0.7972\n",
            "Epoch 73/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4452 - accuracy: 0.8660\n",
            "Epoch 74/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3830 - accuracy: 0.8823\n",
            "Epoch 75/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3707 - accuracy: 0.8833\n",
            "Epoch 76/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3688 - accuracy: 0.8847\n",
            "Epoch 77/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3700 - accuracy: 0.8833\n",
            "Epoch 78/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3735 - accuracy: 0.8825\n",
            "Epoch 79/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3797 - accuracy: 0.8820\n",
            "Epoch 80/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5549 - accuracy: 0.8348\n",
            "Epoch 81/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5558 - accuracy: 0.8346\n",
            "Epoch 82/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4115 - accuracy: 0.8741\n",
            "Epoch 83/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3759 - accuracy: 0.8827\n",
            "Epoch 84/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3722 - accuracy: 0.8824\n",
            "Epoch 85/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3690 - accuracy: 0.8847\n",
            "Epoch 86/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3705 - accuracy: 0.8836\n",
            "Epoch 87/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.3735 - accuracy: 0.8833\n",
            "Epoch 88/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4393 - accuracy: 0.8651\n",
            "Epoch 89/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5790 - accuracy: 0.8266\n",
            "Epoch 90/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4653 - accuracy: 0.8593\n",
            "Epoch 91/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4010 - accuracy: 0.8769\n",
            "Epoch 92/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3769 - accuracy: 0.8815\n",
            "Epoch 93/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3710 - accuracy: 0.8828\n",
            "Epoch 94/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3740 - accuracy: 0.8821\n",
            "Epoch 95/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3749 - accuracy: 0.8828\n",
            "Epoch 96/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3881 - accuracy: 0.8812\n",
            "Epoch 97/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4932 - accuracy: 0.8495\n",
            "Epoch 98/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5031 - accuracy: 0.8470\n",
            "Epoch 99/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4290 - accuracy: 0.8691\n",
            "Epoch 100/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3998 - accuracy: 0.8771\n",
            "Epoch 101/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3862 - accuracy: 0.8797\n",
            "Epoch 102/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3866 - accuracy: 0.8795\n",
            "Epoch 103/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3988 - accuracy: 0.8774\n",
            "Epoch 104/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4082 - accuracy: 0.8736\n",
            "Epoch 105/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4242 - accuracy: 0.8699\n",
            "Epoch 106/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4300 - accuracy: 0.8683\n",
            "Epoch 107/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4343 - accuracy: 0.8666\n",
            "Epoch 108/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4089 - accuracy: 0.8740\n",
            "Epoch 109/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.3954 - accuracy: 0.8773\n",
            "Epoch 110/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4169 - accuracy: 0.8702\n",
            "Epoch 111/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4227 - accuracy: 0.8698\n",
            "Epoch 112/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4147 - accuracy: 0.8717\n",
            "Epoch 113/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4234 - accuracy: 0.8696\n",
            "Epoch 114/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4132 - accuracy: 0.8701\n",
            "Epoch 115/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.3996 - accuracy: 0.8776\n",
            "Epoch 116/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4043 - accuracy: 0.8741\n",
            "Epoch 117/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4003 - accuracy: 0.8772\n",
            "Epoch 118/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4004 - accuracy: 0.8742\n",
            "Epoch 119/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4049 - accuracy: 0.8743\n",
            "Epoch 120/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4231 - accuracy: 0.8701\n",
            "Epoch 121/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4359 - accuracy: 0.8677\n",
            "Epoch 122/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4614 - accuracy: 0.8585\n",
            "Epoch 123/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4531 - accuracy: 0.8609\n",
            "Epoch 124/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4277 - accuracy: 0.8679\n",
            "Epoch 125/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4191 - accuracy: 0.8711\n",
            "Epoch 126/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4154 - accuracy: 0.8721\n",
            "Epoch 127/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4245 - accuracy: 0.8691\n",
            "Epoch 128/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4304 - accuracy: 0.8673\n",
            "Epoch 129/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4401 - accuracy: 0.8650\n",
            "Epoch 130/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4477 - accuracy: 0.8633\n",
            "Epoch 131/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4369 - accuracy: 0.8648\n",
            "Epoch 132/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4347 - accuracy: 0.8675\n",
            "Epoch 133/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4650 - accuracy: 0.8575\n",
            "Epoch 134/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4492 - accuracy: 0.8632\n",
            "Epoch 135/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4299 - accuracy: 0.8665\n",
            "Epoch 136/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4327 - accuracy: 0.8685\n",
            "Epoch 137/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4363 - accuracy: 0.8646\n",
            "Epoch 138/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4301 - accuracy: 0.8697\n",
            "Epoch 139/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4399 - accuracy: 0.8661\n",
            "Epoch 140/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4567 - accuracy: 0.8590\n",
            "Epoch 141/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4434 - accuracy: 0.8644\n",
            "Epoch 142/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4405 - accuracy: 0.8641\n",
            "Epoch 143/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4591 - accuracy: 0.8604\n",
            "Epoch 144/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4946 - accuracy: 0.8458\n",
            "Epoch 145/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4620 - accuracy: 0.8597\n",
            "Epoch 146/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4730 - accuracy: 0.8559\n",
            "Epoch 147/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4466 - accuracy: 0.8627\n",
            "Epoch 148/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4486 - accuracy: 0.8632\n",
            "Epoch 149/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4636 - accuracy: 0.8585\n",
            "Epoch 150/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4861 - accuracy: 0.8514\n",
            "Epoch 151/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4951 - accuracy: 0.8479\n",
            "Epoch 152/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4516 - accuracy: 0.8608\n",
            "Epoch 153/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4338 - accuracy: 0.8674\n",
            "Epoch 154/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4279 - accuracy: 0.8686\n",
            "Epoch 155/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4299 - accuracy: 0.8675\n",
            "Epoch 156/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4356 - accuracy: 0.8666\n",
            "Epoch 157/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4435 - accuracy: 0.8643\n",
            "Epoch 158/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4494 - accuracy: 0.8627\n",
            "Epoch 159/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4496 - accuracy: 0.8603\n",
            "Epoch 160/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.4692 - accuracy: 0.8553\n",
            "Epoch 161/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5163 - accuracy: 0.8432\n",
            "Epoch 162/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5070 - accuracy: 0.8470\n",
            "Epoch 163/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4679 - accuracy: 0.8587\n",
            "Epoch 164/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4458 - accuracy: 0.8631\n",
            "Epoch 165/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4496 - accuracy: 0.8607\n",
            "Epoch 166/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4485 - accuracy: 0.8612\n",
            "Epoch 167/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4588 - accuracy: 0.8588\n",
            "Epoch 168/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4769 - accuracy: 0.8525\n",
            "Epoch 169/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4885 - accuracy: 0.8499\n",
            "Epoch 170/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5005 - accuracy: 0.8477\n",
            "Epoch 171/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4982 - accuracy: 0.8484\n",
            "Epoch 172/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4915 - accuracy: 0.8490\n",
            "Epoch 173/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4726 - accuracy: 0.8560\n",
            "Epoch 174/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.4682 - accuracy: 0.8561\n",
            "Epoch 175/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5083 - accuracy: 0.8447\n",
            "Epoch 176/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5063 - accuracy: 0.8462\n",
            "Epoch 177/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4866 - accuracy: 0.8500\n",
            "Epoch 178/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4713 - accuracy: 0.8560\n",
            "Epoch 179/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4823 - accuracy: 0.8529\n",
            "Epoch 180/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.4798 - accuracy: 0.8520\n",
            "Epoch 181/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5063 - accuracy: 0.8454\n",
            "Epoch 182/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5065 - accuracy: 0.8461\n",
            "Epoch 183/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5598 - accuracy: 0.8303\n",
            "Epoch 184/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5884 - accuracy: 0.8215\n",
            "Epoch 185/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5636 - accuracy: 0.8280\n",
            "Epoch 186/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5391 - accuracy: 0.8350\n",
            "Epoch 187/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5229 - accuracy: 0.8410\n",
            "Epoch 188/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5411 - accuracy: 0.8373\n",
            "Epoch 189/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5296 - accuracy: 0.8387\n",
            "Epoch 190/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5200 - accuracy: 0.8407\n",
            "Epoch 191/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5356 - accuracy: 0.8356\n",
            "Epoch 192/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5305 - accuracy: 0.8392\n",
            "Epoch 193/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5497 - accuracy: 0.8332\n",
            "Epoch 194/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5901 - accuracy: 0.8223\n",
            "Epoch 195/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5668 - accuracy: 0.8288\n",
            "Epoch 196/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5676 - accuracy: 0.8272\n",
            "Epoch 197/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5574 - accuracy: 0.8294\n",
            "Epoch 198/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5376 - accuracy: 0.8365\n",
            "Epoch 199/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5495 - accuracy: 0.8309\n",
            "Epoch 200/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5296 - accuracy: 0.8374\n",
            "Epoch 201/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5395 - accuracy: 0.8351\n",
            "Epoch 202/500\n",
            "688/688 [==============================] - 14s 21ms/step - loss: 0.5465 - accuracy: 0.8331\n",
            "Epoch 203/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5304 - accuracy: 0.8374\n",
            "Epoch 204/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5718 - accuracy: 0.8265\n",
            "Epoch 205/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5389 - accuracy: 0.8350\n",
            "Epoch 206/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5621 - accuracy: 0.8294\n",
            "Epoch 207/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5910 - accuracy: 0.8209\n",
            "Epoch 208/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5664 - accuracy: 0.8285\n",
            "Epoch 209/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5585 - accuracy: 0.8280\n",
            "Epoch 210/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5585 - accuracy: 0.8293\n",
            "Epoch 211/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5473 - accuracy: 0.8331\n",
            "Epoch 212/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5572 - accuracy: 0.8294\n",
            "Epoch 213/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5689 - accuracy: 0.8254\n",
            "Epoch 214/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6195 - accuracy: 0.8137\n",
            "Epoch 215/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.5751 - accuracy: 0.8258\n",
            "Epoch 216/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5937 - accuracy: 0.8213\n",
            "Epoch 217/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6390 - accuracy: 0.8082\n",
            "Epoch 218/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6129 - accuracy: 0.8135\n",
            "Epoch 219/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6119 - accuracy: 0.8127\n",
            "Epoch 220/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.5987 - accuracy: 0.8166\n",
            "Epoch 221/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6561 - accuracy: 0.8049\n",
            "Epoch 222/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6825 - accuracy: 0.7988\n",
            "Epoch 223/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6627 - accuracy: 0.8026\n",
            "Epoch 224/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6600 - accuracy: 0.8007\n",
            "Epoch 225/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6274 - accuracy: 0.8094\n",
            "Epoch 226/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6355 - accuracy: 0.8060\n",
            "Epoch 227/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6623 - accuracy: 0.8001\n",
            "Epoch 228/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6157 - accuracy: 0.8153\n",
            "Epoch 229/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6225 - accuracy: 0.8126\n",
            "Epoch 230/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6528 - accuracy: 0.8037\n",
            "Epoch 231/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6317 - accuracy: 0.8086\n",
            "Epoch 232/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6089 - accuracy: 0.8152\n",
            "Epoch 233/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6263 - accuracy: 0.8098\n",
            "Epoch 234/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6021 - accuracy: 0.8171\n",
            "Epoch 235/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6349 - accuracy: 0.8107\n",
            "Epoch 236/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6532 - accuracy: 0.8037\n",
            "Epoch 237/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7160 - accuracy: 0.7859\n",
            "Epoch 238/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6975 - accuracy: 0.7928\n",
            "Epoch 239/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7264 - accuracy: 0.7855\n",
            "Epoch 240/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6800 - accuracy: 0.7970\n",
            "Epoch 241/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6523 - accuracy: 0.8023\n",
            "Epoch 242/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6156 - accuracy: 0.8138\n",
            "Epoch 243/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6056 - accuracy: 0.8181\n",
            "Epoch 244/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6221 - accuracy: 0.8137\n",
            "Epoch 245/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6368 - accuracy: 0.8091\n",
            "Epoch 246/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6564 - accuracy: 0.8027\n",
            "Epoch 247/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6609 - accuracy: 0.8012\n",
            "Epoch 248/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6626 - accuracy: 0.8019\n",
            "Epoch 249/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6572 - accuracy: 0.7994\n",
            "Epoch 250/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7240 - accuracy: 0.7853\n",
            "Epoch 251/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.7191 - accuracy: 0.7866\n",
            "Epoch 252/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6850 - accuracy: 0.7966\n",
            "Epoch 253/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6595 - accuracy: 0.8016\n",
            "Epoch 254/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6785 - accuracy: 0.7956\n",
            "Epoch 255/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6730 - accuracy: 0.7967\n",
            "Epoch 256/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6539 - accuracy: 0.8025\n",
            "Epoch 257/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6548 - accuracy: 0.8006\n",
            "Epoch 258/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6603 - accuracy: 0.8001\n",
            "Epoch 259/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.6782 - accuracy: 0.7948\n",
            "Epoch 260/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6953 - accuracy: 0.7905\n",
            "Epoch 261/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6710 - accuracy: 0.7991\n",
            "Epoch 262/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7030 - accuracy: 0.7900\n",
            "Epoch 263/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7201 - accuracy: 0.7855\n",
            "Epoch 264/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7069 - accuracy: 0.7894\n",
            "Epoch 265/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.6924 - accuracy: 0.7933\n",
            "Epoch 266/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7227 - accuracy: 0.7824\n",
            "Epoch 267/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7651 - accuracy: 0.7700\n",
            "Epoch 268/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7371 - accuracy: 0.7797\n",
            "Epoch 269/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7233 - accuracy: 0.7837\n",
            "Epoch 270/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7049 - accuracy: 0.7906\n",
            "Epoch 271/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.7380 - accuracy: 0.7800\n",
            "Epoch 272/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8372 - accuracy: 0.7568\n",
            "Epoch 273/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8338 - accuracy: 0.7573\n",
            "Epoch 274/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8193 - accuracy: 0.7569\n",
            "Epoch 275/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8060 - accuracy: 0.7613\n",
            "Epoch 276/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8555 - accuracy: 0.7484\n",
            "Epoch 277/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8382 - accuracy: 0.7544\n",
            "Epoch 278/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8806 - accuracy: 0.7456\n",
            "Epoch 279/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8997 - accuracy: 0.7405\n",
            "Epoch 280/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8813 - accuracy: 0.7412\n",
            "Epoch 281/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8701 - accuracy: 0.7474\n",
            "Epoch 282/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9176 - accuracy: 0.7398\n",
            "Epoch 283/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8420 - accuracy: 0.7509\n",
            "Epoch 284/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8494 - accuracy: 0.7517\n",
            "Epoch 285/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8437 - accuracy: 0.7511\n",
            "Epoch 286/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8500 - accuracy: 0.7498\n",
            "Epoch 287/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8448 - accuracy: 0.7537\n",
            "Epoch 288/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8154 - accuracy: 0.7584\n",
            "Epoch 289/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8091 - accuracy: 0.7634\n",
            "Epoch 290/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8033 - accuracy: 0.7593\n",
            "Epoch 291/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8320 - accuracy: 0.7551\n",
            "Epoch 292/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8972 - accuracy: 0.7384\n",
            "Epoch 293/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8965 - accuracy: 0.7390\n",
            "Epoch 294/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8766 - accuracy: 0.7444\n",
            "Epoch 295/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8679 - accuracy: 0.7478\n",
            "Epoch 296/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8695 - accuracy: 0.7412\n",
            "Epoch 297/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8858 - accuracy: 0.7382\n",
            "Epoch 298/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.8931 - accuracy: 0.7374\n",
            "Epoch 299/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8839 - accuracy: 0.7382\n",
            "Epoch 300/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.8760 - accuracy: 0.7397\n",
            "Epoch 301/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9717 - accuracy: 0.7200\n",
            "Epoch 302/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.0002 - accuracy: 0.7117\n",
            "Epoch 303/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9260 - accuracy: 0.7316\n",
            "Epoch 304/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9127 - accuracy: 0.7346\n",
            "Epoch 305/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9185 - accuracy: 0.7308\n",
            "Epoch 306/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9171 - accuracy: 0.7322\n",
            "Epoch 307/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9190 - accuracy: 0.7368\n",
            "Epoch 308/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9855 - accuracy: 0.7167\n",
            "Epoch 309/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9650 - accuracy: 0.7243\n",
            "Epoch 310/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9880 - accuracy: 0.7149\n",
            "Epoch 311/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 0.9914 - accuracy: 0.7135\n",
            "Epoch 312/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.0008 - accuracy: 0.7132\n",
            "Epoch 313/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.0004 - accuracy: 0.7120\n",
            "Epoch 314/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9827 - accuracy: 0.7167\n",
            "Epoch 315/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9707 - accuracy: 0.7200\n",
            "Epoch 316/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.0090 - accuracy: 0.7114\n",
            "Epoch 317/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.0370 - accuracy: 0.7045\n",
            "Epoch 318/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9925 - accuracy: 0.7117\n",
            "Epoch 319/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9994 - accuracy: 0.7114\n",
            "Epoch 320/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 0.9990 - accuracy: 0.7115\n",
            "Epoch 321/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.2090 - accuracy: 0.6700\n",
            "Epoch 322/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.2438 - accuracy: 0.6616\n",
            "Epoch 323/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1589 - accuracy: 0.6782\n",
            "Epoch 324/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.2053 - accuracy: 0.6654\n",
            "Epoch 325/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1296 - accuracy: 0.6857\n",
            "Epoch 326/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1484 - accuracy: 0.6796\n",
            "Epoch 327/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1150 - accuracy: 0.6858\n",
            "Epoch 328/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1235 - accuracy: 0.6847\n",
            "Epoch 329/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.1559 - accuracy: 0.6765\n",
            "Epoch 330/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4046 - accuracy: 0.6298\n",
            "Epoch 331/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4737 - accuracy: 0.6150\n",
            "Epoch 332/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4408 - accuracy: 0.6234\n",
            "Epoch 333/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4180 - accuracy: 0.6222\n",
            "Epoch 334/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3649 - accuracy: 0.6343\n",
            "Epoch 335/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.2996 - accuracy: 0.6470\n",
            "Epoch 336/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.2725 - accuracy: 0.6496\n",
            "Epoch 337/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3429 - accuracy: 0.6370\n",
            "Epoch 338/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.2794 - accuracy: 0.6501\n",
            "Epoch 339/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4623 - accuracy: 0.6213\n",
            "Epoch 340/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4851 - accuracy: 0.6094\n",
            "Epoch 341/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4491 - accuracy: 0.6158\n",
            "Epoch 342/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4123 - accuracy: 0.6214\n",
            "Epoch 343/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3893 - accuracy: 0.6257\n",
            "Epoch 344/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3779 - accuracy: 0.6237\n",
            "Epoch 345/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.3270 - accuracy: 0.6375\n",
            "Epoch 346/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3000 - accuracy: 0.6456\n",
            "Epoch 347/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3693 - accuracy: 0.6289\n",
            "Epoch 348/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4058 - accuracy: 0.6247\n",
            "Epoch 349/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4132 - accuracy: 0.6249\n",
            "Epoch 350/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3999 - accuracy: 0.6232\n",
            "Epoch 351/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3440 - accuracy: 0.6407\n",
            "Epoch 352/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4207 - accuracy: 0.6239\n",
            "Epoch 353/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4337 - accuracy: 0.6158\n",
            "Epoch 354/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.3403 - accuracy: 0.6364\n",
            "Epoch 355/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4369 - accuracy: 0.6144\n",
            "Epoch 356/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4993 - accuracy: 0.6071\n",
            "Epoch 357/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4650 - accuracy: 0.6082\n",
            "Epoch 358/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4001 - accuracy: 0.6203\n",
            "Epoch 359/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4073 - accuracy: 0.6218\n",
            "Epoch 360/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4294 - accuracy: 0.6154\n",
            "Epoch 361/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4855 - accuracy: 0.6078\n",
            "Epoch 362/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4621 - accuracy: 0.6104\n",
            "Epoch 363/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5374 - accuracy: 0.5964\n",
            "Epoch 364/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5256 - accuracy: 0.5979\n",
            "Epoch 365/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4509 - accuracy: 0.6108\n",
            "Epoch 366/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5229 - accuracy: 0.6018\n",
            "Epoch 367/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6416 - accuracy: 0.5811\n",
            "Epoch 368/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6456 - accuracy: 0.5774\n",
            "Epoch 369/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7514 - accuracy: 0.5639\n",
            "Epoch 370/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7539 - accuracy: 0.5677\n",
            "Epoch 371/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7623 - accuracy: 0.5590\n",
            "Epoch 372/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7051 - accuracy: 0.5685\n",
            "Epoch 373/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6499 - accuracy: 0.5767\n",
            "Epoch 374/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6254 - accuracy: 0.5801\n",
            "Epoch 375/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5696 - accuracy: 0.5906\n",
            "Epoch 376/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5144 - accuracy: 0.5992\n",
            "Epoch 377/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4930 - accuracy: 0.6042\n",
            "Epoch 378/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4967 - accuracy: 0.5998\n",
            "Epoch 379/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5352 - accuracy: 0.5939\n",
            "Epoch 380/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5008 - accuracy: 0.5989\n",
            "Epoch 381/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4681 - accuracy: 0.6039\n",
            "Epoch 382/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4301 - accuracy: 0.6150\n",
            "Epoch 383/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4100 - accuracy: 0.6199\n",
            "Epoch 384/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4630 - accuracy: 0.6061\n",
            "Epoch 385/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5794 - accuracy: 0.5877\n",
            "Epoch 386/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6754 - accuracy: 0.5727\n",
            "Epoch 387/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5982 - accuracy: 0.5801\n",
            "Epoch 388/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6611 - accuracy: 0.5784\n",
            "Epoch 389/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6883 - accuracy: 0.5740\n",
            "Epoch 390/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6806 - accuracy: 0.5665\n",
            "Epoch 391/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6798 - accuracy: 0.5748\n",
            "Epoch 392/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5609 - accuracy: 0.5916\n",
            "Epoch 393/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5587 - accuracy: 0.5900\n",
            "Epoch 394/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5266 - accuracy: 0.5972\n",
            "Epoch 395/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5355 - accuracy: 0.5993\n",
            "Epoch 396/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5623 - accuracy: 0.5889\n",
            "Epoch 397/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5303 - accuracy: 0.5953\n",
            "Epoch 398/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6717 - accuracy: 0.5725\n",
            "Epoch 399/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6199 - accuracy: 0.5781\n",
            "Epoch 400/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5589 - accuracy: 0.5838\n",
            "Epoch 401/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5120 - accuracy: 0.5954\n",
            "Epoch 402/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4821 - accuracy: 0.6037\n",
            "Epoch 403/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5155 - accuracy: 0.5967\n",
            "Epoch 404/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5034 - accuracy: 0.6001\n",
            "Epoch 405/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5090 - accuracy: 0.6001\n",
            "Epoch 406/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.4616 - accuracy: 0.6067\n",
            "Epoch 407/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5646 - accuracy: 0.5875\n",
            "Epoch 408/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5871 - accuracy: 0.5833\n",
            "Epoch 409/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5797 - accuracy: 0.5877\n",
            "Epoch 410/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7484 - accuracy: 0.5609\n",
            "Epoch 411/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7915 - accuracy: 0.5541\n",
            "Epoch 412/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7430 - accuracy: 0.5567\n",
            "Epoch 413/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7287 - accuracy: 0.5595\n",
            "Epoch 414/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6759 - accuracy: 0.5678\n",
            "Epoch 415/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6178 - accuracy: 0.5793\n",
            "Epoch 416/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6144 - accuracy: 0.5768\n",
            "Epoch 417/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7613 - accuracy: 0.5555\n",
            "Epoch 418/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 2.0484 - accuracy: 0.5146\n",
            "Epoch 419/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 2.0018 - accuracy: 0.5195\n",
            "Epoch 420/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9688 - accuracy: 0.5262\n",
            "Epoch 421/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 2.0125 - accuracy: 0.5225\n",
            "Epoch 422/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 2.1931 - accuracy: 0.4897\n",
            "Epoch 423/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9830 - accuracy: 0.5141\n",
            "Epoch 424/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9645 - accuracy: 0.5237\n",
            "Epoch 425/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9336 - accuracy: 0.5247\n",
            "Epoch 426/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.8564 - accuracy: 0.5337\n",
            "Epoch 427/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8142 - accuracy: 0.5423\n",
            "Epoch 428/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7908 - accuracy: 0.5460\n",
            "Epoch 429/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.8011 - accuracy: 0.5469\n",
            "Epoch 430/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.9726 - accuracy: 0.5271\n",
            "Epoch 431/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9923 - accuracy: 0.5115\n",
            "Epoch 432/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.9163 - accuracy: 0.5282\n",
            "Epoch 433/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8220 - accuracy: 0.5388\n",
            "Epoch 434/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8032 - accuracy: 0.5460\n",
            "Epoch 435/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7584 - accuracy: 0.5504\n",
            "Epoch 436/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.7991 - accuracy: 0.5441\n",
            "Epoch 437/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7928 - accuracy: 0.5433\n",
            "Epoch 438/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7557 - accuracy: 0.5480\n",
            "Epoch 439/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8796 - accuracy: 0.5310\n",
            "Epoch 440/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.9783 - accuracy: 0.5182\n",
            "Epoch 441/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 2.0167 - accuracy: 0.5086\n",
            "Epoch 442/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 2.0029 - accuracy: 0.5176\n",
            "Epoch 443/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.9517 - accuracy: 0.5305\n",
            "Epoch 444/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8784 - accuracy: 0.5354\n",
            "Epoch 445/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8610 - accuracy: 0.5322\n",
            "Epoch 446/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8631 - accuracy: 0.5357\n",
            "Epoch 447/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7876 - accuracy: 0.5469\n",
            "Epoch 448/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8286 - accuracy: 0.5403\n",
            "Epoch 449/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7626 - accuracy: 0.5485\n",
            "Epoch 450/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8317 - accuracy: 0.5386\n",
            "Epoch 451/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7822 - accuracy: 0.5455\n",
            "Epoch 452/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7817 - accuracy: 0.5454\n",
            "Epoch 453/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8574 - accuracy: 0.5327\n",
            "Epoch 454/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8307 - accuracy: 0.5369\n",
            "Epoch 455/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7930 - accuracy: 0.5454\n",
            "Epoch 456/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7328 - accuracy: 0.5520\n",
            "Epoch 457/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6686 - accuracy: 0.5661\n",
            "Epoch 458/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6953 - accuracy: 0.5635\n",
            "Epoch 459/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8250 - accuracy: 0.5395\n",
            "Epoch 460/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7894 - accuracy: 0.5409\n",
            "Epoch 461/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7268 - accuracy: 0.5555\n",
            "Epoch 462/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7191 - accuracy: 0.5551\n",
            "Epoch 463/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7656 - accuracy: 0.5484\n",
            "Epoch 464/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8349 - accuracy: 0.5378\n",
            "Epoch 465/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8579 - accuracy: 0.5344\n",
            "Epoch 466/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7371 - accuracy: 0.5531\n",
            "Epoch 467/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6877 - accuracy: 0.5616\n",
            "Epoch 468/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6508 - accuracy: 0.5693\n",
            "Epoch 469/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6134 - accuracy: 0.5720\n",
            "Epoch 470/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6242 - accuracy: 0.5748\n",
            "Epoch 471/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6822 - accuracy: 0.5644\n",
            "Epoch 472/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6573 - accuracy: 0.5716\n",
            "Epoch 473/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7922 - accuracy: 0.5569\n",
            "Epoch 474/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8043 - accuracy: 0.5498\n",
            "Epoch 475/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8027 - accuracy: 0.5495\n",
            "Epoch 476/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6293 - accuracy: 0.5737\n",
            "Epoch 477/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6250 - accuracy: 0.5796\n",
            "Epoch 478/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6372 - accuracy: 0.5790\n",
            "Epoch 479/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6196 - accuracy: 0.5787\n",
            "Epoch 480/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5787 - accuracy: 0.5833\n",
            "Epoch 481/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5218 - accuracy: 0.5956\n",
            "Epoch 482/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5486 - accuracy: 0.5906\n",
            "Epoch 483/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5469 - accuracy: 0.5915\n",
            "Epoch 484/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6299 - accuracy: 0.5804\n",
            "Epoch 485/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6310 - accuracy: 0.5782\n",
            "Epoch 486/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6096 - accuracy: 0.5799\n",
            "Epoch 487/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6044 - accuracy: 0.5842\n",
            "Epoch 488/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5358 - accuracy: 0.5899\n",
            "Epoch 489/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4828 - accuracy: 0.6016\n",
            "Epoch 490/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.4854 - accuracy: 0.6031\n",
            "Epoch 491/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.5552 - accuracy: 0.5900\n",
            "Epoch 492/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5930 - accuracy: 0.5792\n",
            "Epoch 493/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6164 - accuracy: 0.5725\n",
            "Epoch 494/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.6096 - accuracy: 0.5749\n",
            "Epoch 495/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5356 - accuracy: 0.5879\n",
            "Epoch 496/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.5286 - accuracy: 0.5889\n",
            "Epoch 497/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7164 - accuracy: 0.5650\n",
            "Epoch 498/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.8014 - accuracy: 0.5503\n",
            "Epoch 499/500\n",
            "688/688 [==============================] - 15s 22ms/step - loss: 1.7160 - accuracy: 0.5644\n",
            "Epoch 500/500\n",
            "688/688 [==============================] - 15s 21ms/step - loss: 1.6828 - accuracy: 0.5680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am PANDA, Paradgim-based Artificial Neural Dialogue Agent. An AI Language Model which is able to predict next sequence of words based on the input sequence of words.\n",
            "\n",
            " â†³ (user) : hello\n",
            "will be well it happen i today are you going to move there because well whatever the world new world war ii monument on the\n",
            "\n",
            " â†³ (user) : what is your name?\n",
            "favorite movie i couldn't wait to eat been a lot of good deals as usual money do you believe the cat doesn't care money in\n",
            "\n",
            " â†³ (user) : what are you talking about\n",
            "sunday is mother's day yes really much water is nice but what's wrong with it no the banana was delicious you have a big dictionary\n",
            "\n",
            " â†³ (user) : are you hungry\n",
            "it's ninety degrees outside it's not to be a job yes you chased that i thought you just come back to shoppers i'm still waiting\n",
            "\n",
            " â†³ (user) : okay are you talking about the weather\n",
            "you have to be doing tell to the bathroom you drink a good nose for thatÂ—cigarettes stink that was a beautiful i was nearby too\n",
            "\n",
            " â†³ (user) : i am not in bathroom\n",
            "you don't you i want to move there in heaven with me i'm really tired to give you a nose do sunday of course it\n",
            "\n",
            " â†³ (user) : i don't have what?\n",
            "you can come to do that in i watched it no it's at the pollution in town the ground so we've got a lot of\n",
            "\n",
            " â†³ (user) : i haven't went to anywhere\n",
            "a lot of dogs but they don't they call the front desk who served in world war ii veterans is him as in a m\n",
            "\n",
            " â†³ (user) : dogs?\n",
            "it's not too bitter for you it's an hour for a close game that's no good i'm going to give me that you didn't have\n",
            "\n",
            " â†³ (user) : we are not playing anything\n",
            "they're you have any other skills well i want to go alone see and minutes i'm glad that i was really fun out to the\n",
            "\n",
            " â†³ (user) : you liked to talk me?\n",
            "to make you get free food in the woods not time to eat money than you so we can go on the assignments up please\n",
            "\n",
            " â†³ (user) : are you hungry\n",
            "it's ninety degrees outside it's not to be a job yes you chased that i thought you just come back to shoppers i'm still waiting\n",
            "\n",
            " â†³ (user) : okay i got\n",
            "seats it gets a good card about you looking for you sure it's almost empty and it's so n half an hour to you sure\n",
            "\n",
            " â†³ (user) : bye\n",
            "what did you do what else do we need to save money in the best of the and the best time just killed read it\n",
            "\n",
            " â†³ (user) : hmmm\n",
            "what did you do what else do we need to save money in the best of the and the best time just killed read it\n",
            "\n",
            " â†³ (user) : good bye\n",
            "luck with school how's it a hospital is more than but someone was a good person too much about it's to a good person just\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d63806a58a5c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n â†³ (user) : \"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpanda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpanda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}